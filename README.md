# Gesture Generation and Embodied Conversational Agents

Source:
[Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective Expression Learning](https://github.com/UttaranB127/speech2affective_gestures)

Github does not include the venv, ted_db, outputs, models, or data folders for storage reasons (each is several gb, totaling about 80 gb)

In order to run, assure you have the libraries with appropriate versions mentioned on the link. 
Then, run python main_v2.py -c config/multimodal_context_v2.yml


Project is in progress, will be updated.
