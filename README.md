# Gesture Generation and Embodied Conversational Agents

Source:
[Speech2AffectiveGestures: Synthesizing Co-Speech Gestures with Generative Adversarial Affective Expression Learning](https://github.com/UttaranB127/speech2affective_gestures)

Github does not include the venv, ted_db, outputs, models, or data folders for storage reasons (each is several gb, totaling about 80 gb)

In order to run, assure you have the libraries with appropriate versions mentioned on the link. 
Then, run python main_v2.py -c config/multimodal_context_v2.yml

Full details of my work can be seen via the final research paper on Affect_Gesture_Generation_and_Embodied_Conversational_Agents___CS_549.pdf
Will publish the paper in the near future


